\chapter{Аналитическая часть}

Поиск по словарю является задачей, которая стоит во многих сферах программирования. Поиск по словарю является задачей, которую требуется решать быстро, поэтому необходимы методы для оптимизации данной задачи.


\section{Алгоритм полного перебора}

Алгоритмом полного перебора \cite{brute} называют метод решения задачи, при котором по очереди рассматриваются все возможные варианты. В нашем случае мы последовательно будем перебирать элементы словаря до тех пор, пока не найдём нужный. Сложность такого алгоритма зависит от количества всех возможных решений, а время решения может потребовать экспоненциального времени работы. 

Пусть алгоритм нашёл элемент на первом сравнении, тогда, в лучшем случае, будет затрачено $k_0+k_1$ операций, на втором - $k_0+2k_1$, на последней - $k_0+Nk_1$. Тогда средняя трудоёмкость может быть рассчитана по формуле \ref{eq:tbrute}, где $\Omega$ -- множество всех возможных случаев.

\begin{equation} \label{eq:tbrute}
\begin {aligned}
\sum\limits_{i\in\Omega} p_i\cdot f_i = & (k_0 + k_1)\frac{1}{N+1}+(k_0+2k_1)\frac{1}{N+1} +\\
&+ (k_0+3k_1)\frac{1}{N+1}+(k_0+Nk_1)\frac{1}{N+1}+(k_0+Nk_1)\frac{1}{N+1} =\\
&= k_0\frac{N+1}{N+1}+k_1+\frac{1+2+...+N+N}{N+1} = \\
&=k_0+k_1(\frac{N}{N+1}+\frac{N}{2}) = k_0+k_1(1+\frac{N}{2}-\frac{1}{N+1})
\end{aligned}
\end{equation}
\section{Частотный анализ}

Прежде чем перейти к рассмотрению алгоритма эффективного поиска по словарю стоит рассмотреть процедуру частотного анализа \cite{fa}, которая лежит в основе данного алгоритма. Чтобы провести частотный анализ нужно взять первый элемент каждого значения в словаре по ключу и подсчитать частотную характеристику, т.е. сколько раз этот элемент встречается в качестве первого элемента. 

Таким образом мы повторяем алгоритм для $i$-го элемента каждого значения, вычисляя для каждого $i$-го набора частотную характеристику.

\section{Алгоритм эффективного поиска по словарю}

Алгоритм на вход получает словарь и на его основе составляется частотный анализ. По полученным значениям словарь разбивается на сегменты так, что все элементы с одинаковым первым элементом оказываются в одном сегменте. 

Сегменты упорядочиваются по значению частотной характеристики так, чтобы к элементы с наибольшей частотной характеристикой был самый быстрый доступ. 

Далее каждый сегмент упорядочивается по значению. Это необходимо для реализации бинарного поиска, который обеспечит эффективный поиск в сегменте при сложности $O(\log n)$

Таким образом, сначала выбирается нужный сегмент, а затем в нем проводится бинарный поиск нужного элемента. Средняя трудоёмкость при длине алфавита $M$ может быть рассчитана по формуле \ref{eq:tfa}. 

\begin{equation} \label{eq:tfa}
	\sum\limits_{i\in[1, M]} (f_{\text{выбор i-го сегмента}}+f_{\text{поиск в i-ом сегменте}}) \cdot p_i
\end{equation}


\section*{Вывод}

Были рассмотрены алгоритмы полного перебора и эффективного поиска по словарю и их трудоёмкость. Так же был рассмотрен частотный анализ, являющийся частью одного из рассмотренных алгоритмов.
